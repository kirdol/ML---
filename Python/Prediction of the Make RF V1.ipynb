{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5613289760348584\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           2       0.67      0.71      0.69        68\n",
      "           3       0.73      0.89      0.80        18\n",
      "           4       0.12      0.20      0.15         5\n",
      "           5       0.78      0.93      0.85        30\n",
      "           6       0.79      0.76      0.78       242\n",
      "           8       0.00      0.00      0.00         2\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       0.84      0.87      0.85       473\n",
      "          12       1.00      1.00      1.00         1\n",
      "          14       0.91      0.86      0.89        36\n",
      "          15       0.50      1.00      0.67         1\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       0.29      0.26      0.27       144\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.67      0.50      0.57         4\n",
      "          23       0.72      0.64      0.68       138\n",
      "          24       0.26      0.30      0.28       813\n",
      "          25       0.26      0.25      0.25       162\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.67      0.67      0.67         3\n",
      "          29       0.00      0.00      0.00        10\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.53      0.57      0.55       531\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.15      0.12      0.13        34\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.96      0.92      0.94        52\n",
      "          39       1.00      0.82      0.90        17\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.66      0.59      0.62       771\n",
      "          42       0.17      0.15      0.16       567\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.71      0.62      0.67        16\n",
      "          45       0.20      0.17      0.19        23\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.64      0.68      0.66       232\n",
      "          50       0.25      0.33      0.29         3\n",
      "          51       0.41      0.46      0.44       171\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       0.88      0.88      0.88        93\n",
      "          56       0.47      0.50      0.48        88\n",
      "          57       0.62      0.83      0.71         6\n",
      "          59       0.77      0.67      0.72       117\n",
      "          60       0.66      0.74      0.70       205\n",
      "          62       0.50      1.00      0.67         1\n",
      "          64       0.44      0.34      0.38       167\n",
      "          65       1.00      1.00      1.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.81      0.72      0.76        36\n",
      "          69       0.91      0.90      0.91        59\n",
      "          70       0.75      0.73      0.74       126\n",
      "          71       0.40      0.40      0.40        85\n",
      "          74       0.88      0.94      0.91        16\n",
      "          75       0.50      1.00      0.67         4\n",
      "          76       0.86      0.98      0.91        87\n",
      "          78       0.90      0.83      0.86        42\n",
      "          79       0.71      0.50      0.59        10\n",
      "          80       0.52      0.52      0.52       227\n",
      "          81       1.00      0.67      0.80        15\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.89      0.94      0.91       368\n",
      "          84       0.08      0.08      0.08       118\n",
      "          85       0.33      0.50      0.40         2\n",
      "          86       0.47      0.46      0.47       223\n",
      "          87       1.00      1.00      1.00         1\n",
      "          89       0.72      0.59      0.65       339\n",
      "          90       0.07      0.07      0.07       104\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       0.69      0.73      0.71        15\n",
      "          98       1.00      0.50      0.67         2\n",
      "          99       0.07      0.07      0.07       104\n",
      "         100       0.00      0.00      0.00         3\n",
      "         101       0.18      0.17      0.18       187\n",
      "         102       0.91      0.95      0.93       255\n",
      "         103       0.00      0.00      0.00         0\n",
      "         105       1.00      0.50      0.67         2\n",
      "         106       0.93      0.90      0.92        31\n",
      "         108       0.57      0.80      0.67        10\n",
      "         109       1.00      0.33      0.50         3\n",
      "         110       0.93      0.89      0.91        47\n",
      "         111       0.79      0.71      0.75        21\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         116       0.53      0.51      0.52        85\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       0.00      0.00      0.00         2\n",
      "         119       0.37      0.47      0.41        49\n",
      "         120       0.17      0.25      0.20         8\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       1.00      1.00      1.00         2\n",
      "         123       0.00      0.00      0.00         4\n",
      "         124       0.76      0.77      0.76       195\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.42      0.46      0.44       106\n",
      "         128       0.33      0.50      0.40         2\n",
      "         129       0.96      0.81      0.88        31\n",
      "         130       0.00      0.00      0.00         1\n",
      "         131       0.59      0.64      0.61       439\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.64      0.72      0.68       257\n",
      "         137       0.75      0.71      0.73       164\n",
      "         138       0.38      0.50      0.43         6\n",
      "         140       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.56      9180\n",
      "   macro avg       0.50      0.50      0.49      9180\n",
      "weighted avg       0.56      0.56      0.56      9180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Vehicle MPG - 1984 to 2023.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Selecting specific columns for features and target\n",
    "features = ['Engine Displacement', 'Drive', 'Transmission', 'Vehicle Class', 'Fuel Type 1', 'Model Year']\n",
    "target = 'Make'\n",
    "\n",
    "# Filter the dataset to include only the selected features and the target\n",
    "data = data[features + [target]]\n",
    "\n",
    "# Handling categorical variables with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Separating features and target\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creating a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluating the results\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# If you want to inverse transform the predicted labels back to original labels\n",
    "# y_pred_labels = label_encoders[target].inverse_transform(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OverSampling Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: parse error near `-m'\n",
      "Accuracy: 0.55\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         4\n",
      "           2       0.52      0.69      0.59        68\n",
      "           3       0.67      0.89      0.76        18\n",
      "           4       0.33      1.00      0.50         5\n",
      "           5       0.75      0.90      0.82        30\n",
      "           6       0.78      0.73      0.76       242\n",
      "           8       0.00      0.00      0.00         2\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       0.88      0.78      0.83       473\n",
      "          12       1.00      1.00      1.00         1\n",
      "          14       0.69      0.86      0.77        36\n",
      "          15       0.50      1.00      0.67         1\n",
      "          16       0.00      0.00      0.00         2\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       1.00      1.00      1.00         4\n",
      "          19       0.22      0.22      0.22       144\n",
      "          20       0.00      0.00      0.00         1\n",
      "          22       0.75      0.75      0.75         4\n",
      "          23       0.63      0.68      0.66       138\n",
      "          24       0.28      0.18      0.22       813\n",
      "          25       0.31      0.38      0.34       162\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.67      0.67      0.67         3\n",
      "          29       0.00      0.00      0.00        10\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.69      0.48      0.57       531\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.10      0.24      0.14        34\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.90      0.88      0.89        52\n",
      "          39       0.67      0.82      0.74        17\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.77      0.51      0.61       771\n",
      "          42       0.29      0.31      0.30       567\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.36      0.75      0.49        16\n",
      "          45       0.22      0.52      0.31        23\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.62      0.64      0.63       232\n",
      "          50       0.20      0.33      0.25         3\n",
      "          51       0.40      0.44      0.42       171\n",
      "          53       0.67      1.00      0.80         2\n",
      "          54       0.74      0.90      0.81        93\n",
      "          56       0.30      0.61      0.40        88\n",
      "          57       0.80      0.67      0.73         6\n",
      "          59       0.66      0.68      0.67       117\n",
      "          60       0.65      0.71      0.68       205\n",
      "          62       0.50      1.00      0.67         1\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.39      0.37      0.38       167\n",
      "          65       1.00      1.00      1.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.79      0.86      0.83        36\n",
      "          69       0.76      0.90      0.82        59\n",
      "          70       0.64      0.75      0.69       126\n",
      "          71       0.31      0.55      0.40        85\n",
      "          74       0.84      1.00      0.91        16\n",
      "          75       0.50      1.00      0.67         4\n",
      "          76       0.86      0.98      0.91        87\n",
      "          78       0.78      0.83      0.80        42\n",
      "          79       0.80      0.80      0.80        10\n",
      "          80       0.49      0.51      0.50       227\n",
      "          81       0.88      0.93      0.90        15\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.91      0.90      0.91       368\n",
      "          84       0.24      0.37      0.29       118\n",
      "          85       0.14      0.50      0.22         2\n",
      "          86       0.48      0.45      0.46       223\n",
      "          87       1.00      1.00      1.00         1\n",
      "          89       0.74      0.54      0.62       339\n",
      "          90       0.09      0.19      0.12       104\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         0\n",
      "          96       1.00      1.00      1.00         1\n",
      "          97       0.41      0.87      0.55        15\n",
      "          98       1.00      1.00      1.00         2\n",
      "          99       0.15      0.31      0.21       104\n",
      "         100       0.00      0.00      0.00         3\n",
      "         101       0.23      0.20      0.21       187\n",
      "         102       0.91      0.92      0.92       255\n",
      "         103       0.00      0.00      0.00         0\n",
      "         105       1.00      1.00      1.00         2\n",
      "         106       0.91      0.97      0.94        31\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.23      0.80      0.36        10\n",
      "         109       0.50      1.00      0.67         3\n",
      "         110       0.93      0.89      0.91        47\n",
      "         111       0.88      0.71      0.79        21\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         116       0.43      0.54      0.48        85\n",
      "         117       1.00      1.00      1.00         1\n",
      "         118       0.50      0.50      0.50         2\n",
      "         119       0.34      0.55      0.42        49\n",
      "         120       0.11      0.25      0.15         8\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       1.00      1.00      1.00         2\n",
      "         123       0.25      0.25      0.25         4\n",
      "         124       0.75      0.75      0.75       195\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.39      0.51      0.44       106\n",
      "         128       0.33      1.00      0.50         2\n",
      "         129       0.77      0.87      0.82        31\n",
      "         130       0.50      1.00      0.67         1\n",
      "         131       0.67      0.55      0.60       439\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.70      0.69      0.70       257\n",
      "         137       0.79      0.65      0.71       164\n",
      "         138       0.33      0.67      0.44         6\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.55      9180\n",
      "   macro avg       0.47      0.54      0.49      9180\n",
      "weighted avg       0.58      0.55      0.56      9180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install imbalanced-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Vehicle MPG - 1984 to 2023.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Selecting specific columns for features and target\n",
    "features = ['Engine Displacement', 'Drive', 'Transmission', 'Vehicle Class', 'Fuel Type 1', 'Model Year']\n",
    "target = 'Make'\n",
    "data = data[features + [target]]\n",
    "\n",
    "# Handling categorical variables with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Imputing missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[features] = imputer.fit_transform(data[features])\n",
    "\n",
    "# Separating features and target\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Applying oversampling\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_os, y_train_os = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Creating and training the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_os, y_train_os)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluating the results\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UnderSampling Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from imbalanced-learn) (3.4.0)\n",
      "Accuracy: 0.08660130718954248\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.25      0.02         4\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.04      0.12      0.06        68\n",
      "           3       0.09      0.44      0.14        18\n",
      "           4       0.01      0.60      0.02         5\n",
      "           5       0.32      0.40      0.36        30\n",
      "           6       0.14      0.06      0.09       242\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.10      0.50      0.17         2\n",
      "           9       0.00      0.00      0.00         0\n",
      "          10       0.09      1.00      0.17         1\n",
      "          11       0.40      0.05      0.09       473\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         0\n",
      "          14       0.10      0.28      0.15        36\n",
      "          15       0.03      1.00      0.06         1\n",
      "          16       0.04      1.00      0.07         2\n",
      "          17       0.00      0.00      0.00         1\n",
      "          18       0.20      0.25      0.22         4\n",
      "          19       0.09      0.04      0.06       144\n",
      "          20       0.05      1.00      0.09         1\n",
      "          21       0.00      0.00      0.00         0\n",
      "          22       0.00      0.00      0.00         4\n",
      "          23       0.21      0.04      0.07       138\n",
      "          24       0.44      0.04      0.08       813\n",
      "          25       0.10      0.07      0.09       162\n",
      "          26       0.00      0.00      0.00         0\n",
      "          27       0.00      0.00      0.00         3\n",
      "          28       0.00      0.00      0.00         0\n",
      "          29       0.03      0.50      0.06        10\n",
      "          30       0.00      0.00      0.00         3\n",
      "          31       0.10      0.01      0.02       531\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.07      0.21      0.10        34\n",
      "          34       0.00      0.00      0.00         0\n",
      "          35       0.12      1.00      0.22         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.03      0.50      0.06         2\n",
      "          38       0.24      0.13      0.17        52\n",
      "          39       0.02      0.06      0.03        17\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.43      0.09      0.14       771\n",
      "          42       0.30      0.18      0.23       567\n",
      "          43       0.00      0.00      0.00         0\n",
      "          44       0.02      0.19      0.03        16\n",
      "          45       0.03      0.09      0.04        23\n",
      "          46       0.00      0.00      0.00         0\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         0\n",
      "          49       0.16      0.05      0.08       232\n",
      "          50       0.01      1.00      0.01         3\n",
      "          51       0.02      0.02      0.02       171\n",
      "          53       0.02      0.50      0.04         2\n",
      "          54       0.23      0.23      0.23        93\n",
      "          55       0.00      0.00      0.00         0\n",
      "          56       0.08      0.20      0.12        88\n",
      "          57       0.03      0.50      0.06         6\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.29      0.14      0.18       117\n",
      "          60       0.12      0.09      0.10       205\n",
      "          61       0.00      0.00      0.00         0\n",
      "          62       0.04      1.00      0.07         1\n",
      "          63       0.00      0.00      0.00         0\n",
      "          64       0.15      0.14      0.15       167\n",
      "          65       0.20      1.00      0.33         1\n",
      "          66       0.00      0.00      0.00         0\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.52      0.42      0.46        36\n",
      "          69       0.13      0.47      0.20        59\n",
      "          70       0.02      0.02      0.02       126\n",
      "          71       0.18      0.20      0.19        85\n",
      "          72       0.00      0.00      0.00         0\n",
      "          73       0.00      0.00      0.00         0\n",
      "          74       0.00      0.00      0.00        16\n",
      "          75       0.17      1.00      0.29         4\n",
      "          76       0.16      0.28      0.20        87\n",
      "          77       0.00      0.00      0.00         0\n",
      "          78       0.23      0.19      0.21        42\n",
      "          79       0.11      1.00      0.20        10\n",
      "          80       0.00      0.00      0.00       227\n",
      "          81       0.11      0.33      0.17        15\n",
      "          82       0.03      1.00      0.06         1\n",
      "          83       0.07      0.00      0.01       368\n",
      "          84       0.11      0.03      0.05       118\n",
      "          85       0.00      0.00      0.00         2\n",
      "          86       0.05      0.02      0.03       223\n",
      "          87       0.01      1.00      0.03         1\n",
      "          88       0.00      0.00      0.00         0\n",
      "          89       0.04      0.01      0.01       339\n",
      "          90       0.08      0.03      0.04       104\n",
      "          91       0.00      0.00      0.00         0\n",
      "          92       0.00      0.00      0.00         1\n",
      "          93       0.00      0.00      0.00         0\n",
      "          94       0.00      0.00      0.00         0\n",
      "          95       0.00      0.00      0.00         0\n",
      "          96       0.04      1.00      0.07         1\n",
      "          97       0.01      0.07      0.02        15\n",
      "          98       0.17      1.00      0.29         2\n",
      "          99       0.13      0.16      0.14       104\n",
      "         100       0.03      0.33      0.06         3\n",
      "         101       0.04      0.02      0.02       187\n",
      "         102       0.23      0.03      0.06       255\n",
      "         103       0.00      0.00      0.00         0\n",
      "         104       0.00      0.00      0.00         0\n",
      "         105       0.05      1.00      0.10         2\n",
      "         106       0.41      0.42      0.41        31\n",
      "         107       0.00      0.00      0.00         0\n",
      "         108       0.03      0.20      0.05        10\n",
      "         109       0.20      0.67      0.31         3\n",
      "         110       0.41      0.72      0.53        47\n",
      "         111       0.00      0.00      0.00        21\n",
      "         112       0.17      1.00      0.29         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         0\n",
      "         115       0.00      0.00      0.00         0\n",
      "         116       0.10      0.18      0.13        85\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.02      0.50      0.03         2\n",
      "         119       0.09      0.20      0.13        49\n",
      "         120       0.00      0.00      0.00         8\n",
      "         121       0.00      0.00      0.00         1\n",
      "         122       0.00      0.00      0.00         2\n",
      "         123       0.05      1.00      0.10         4\n",
      "         124       0.14      0.05      0.08       195\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.06      0.13      0.08       106\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       0.02      1.00      0.03         2\n",
      "         129       0.38      0.55      0.45        31\n",
      "         130       0.03      1.00      0.06         1\n",
      "         131       0.11      0.02      0.03       439\n",
      "         132       0.00      0.00      0.00         0\n",
      "         133       0.00      0.00      0.00         0\n",
      "         134       0.00      0.00      0.00         0\n",
      "         135       0.00      0.00      0.00         1\n",
      "         136       0.11      0.05      0.07       257\n",
      "         137       0.04      0.03      0.03       164\n",
      "         138       0.00      0.00      0.00         6\n",
      "         139       0.00      0.00      0.00         0\n",
      "         140       0.29      0.62      0.40         8\n",
      "\n",
      "    accuracy                           0.09      9180\n",
      "   macro avg       0.08      0.24      0.08      9180\n",
      "weighted avg       0.19      0.09      0.09      9180\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imbalanced-learn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Vehicle MPG - 1984 to 2023.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Selecting specific columns for features and target\n",
    "features = ['Engine Displacement', 'Drive', 'Transmission', 'Vehicle Class', 'Fuel Type 1', 'Model Year']\n",
    "target = 'Make'\n",
    "data = data[features + [target]]\n",
    "\n",
    "# Handling categorical variables with Label Encoding\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Imputing missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[features] = imputer.fit_transform(data[features])\n",
    "\n",
    "# Separating features and target\n",
    "X = data.drop(target, axis=1)\n",
    "y = data[target]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Applying undersampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_train_us, y_train_us = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Creating and training the Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train_us, y_train_us)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluating the results\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
