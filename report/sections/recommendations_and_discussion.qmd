# Summary of what was observed from the results

In first hand, we did classification trees to make our predictions. We have noticed that with our "Base" Decision Tree, our model was encountering overfitting, with a training accuracy higher than our test accuracy. We have then used the 10 K-Fold CV in order to assess the performance of our model and we noticed that our accuracy score reached approx. 70%. in this case, overfitting was not fixed. 

Then, we have decided to prune the tree fo fight against overfitting. Our results showed that there is a trade of between the accuracy and the overfittingness when playing with the max_depth hyperparameter. In overall, a max_depth of 10 seems to be the best tradeoff between accuracy and overfitting. 

We have been then able to show the variable importance, showing that the top 3 most important features figure in order : the engine displacement, the model of the year and the class of the vehicle. 

Finally, we have used re-sampling in order to fight class unbalances. We have been able to have a much better model with less overfitting and a good accuracy by applying this method (around 90% of test set accuracy). 

For the neural networks model to predict the make (brand) of a vehicle based on its technical characteristics, we managed to train a model with a high kappa score of almost 70%. We have been working with unbalanced classes. Our first neural network model was trained without addressing this problem. For this reason, our first model was very poor at predicting the minority class. To remedy this issue, we applied weighted classes to the loss function so that the model could give more importance to the minority class. We then had to address the presence of overfitting. The model’s validation and test accuracy were noticeably higher than the training accuracy. We applied a technique that we discovered but hadn’t seen in class called dropout layers to our model to mitigate this issue. This technique was interesting to work with. As expected, we saw that the validation accuracy was higher than the test and training accuracy. This is due to the way dropout layers are applied to the model. Some of the neurons are only disabled during the training phase and not during the testing phase. We decided to tune this hyperparameter to reduce the gap between the validation and test accuracy while ensuring not to drop our accuracy too much. In the end, we managed to obtain a model after 150 epochs that had a kappa score and an accuracy on the test set of 70%. We can say that the model is able to predict the make of a vehicle based on its technical characteristics with good accuracy.

To enhance the performance of our neural network models, we should explore novel techniques and alternative methodologies to address the various challenges encountered. In dealing with unbalanced data, techniques such as downsampling or resampling, similar to those utilized in our classification model, may prove beneficial. To address the issue of overfitting, the application of cross-validation or bootstrap methods is recommended. Furthermore, optimizing additional hyperparameters could contribute to further improvements in our model’s performance.

# Implications for the business (link with the context and the initial objectives of the study)

# Limitations (this may be the subject of a separated section). An opening is often expected here: “What next?” “What can be done for improvement”, etc.?

