<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.553">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>results_neural_network</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="results_neural_network_files/libs/clipboard/clipboard.min.js"></script>
<script src="results_neural_network_files/libs/quarto-html/quarto.js"></script>
<script src="results_neural_network_files/libs/quarto-html/popper.min.js"></script>
<script src="results_neural_network_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="results_neural_network_files/libs/quarto-html/anchor.min.js"></script>
<link href="results_neural_network_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="results_neural_network_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="results_neural_network_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="results_neural_network_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="results_neural_network_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="neural-network" class="level1">
<h1>Neural Network</h1>
<p>In this section, we will build a neural network model to predict the make of a car based on the features at our disposal. We will preprocess the data, split it into training and testing sets, define the neural network architecture, compile the model, train it and evaluate its performance.</p>
<section id="preprocessing-and-splitting-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing-and-splitting-the-data">Preprocessing and splitting the data</h2>
<p>The dataset contains different types of data. Some columns are numerical (like “city_mpg_fuel_type_1” or “charge_time_240v”), and some are categorical (“vehicle_class” or “fuel_type”). We identify and separate these two types of columns. Separating numerical and categorical columns is an essential step in data preprocessing because they require different types of handling to prepare them for machine learning algorithms. The numerical columns need to be scaled by adjusting them so they have a mean of zero and a standard deviation of one, which helps the machine learning algorithm perform better. While the categorical columns need to be one-hot encoded which creates a binary column a format that the machine learning model can understand.</p>
<p>The data is split into two parts: training and testing. The training set is used to train the model, and the testing set is used to evaluate its performance. This split ensures that we can test how well the model generalizes to new, unseen data.</p>
<section id="building-the-neural-network-models-and-training-them" class="level3">
<h3 class="anchored" data-anchor-id="building-the-neural-network-models-and-training-them">Building the neural network models and training them</h3>
<section id="base-neural-network" class="level4">
<h4 class="anchored" data-anchor-id="base-neural-network">Base Neural Network</h4>
<p>We chose to use a neural network. This neural network consists of layers of neurons, where each layer applies transformations to the data. The first layer takes the input features. Then some Hidden layers help the model learn complex patterns. In the end, the output layer predicts the probability of each car manufacturer. The first layes, the input layer, takes the input features. The second layers is set to 128 neurons, the third to 64 neurons and the last layer, the output layer, has as many neurons as there are car manufacturers. The activation function used in the hidden layers is the Rectified Linear Unit (ReLU), and the output layer uses the Softmax activation function. The model is compiled with the Adam optimizer and the categorical crossentropy loss function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the neural network model</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>model_no_dropout <span class="op">=</span> Sequential([</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    Input(shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>],)),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    Dense(y_train.shape[<span class="dv">1</span>], activation<span class="op">=</span><span class="st">'softmax'</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We used activation functions in the hidden layers to introduce non-linearity into the model. The ReLU activation function is used in the hidden layers because it is computationally efficient and helps the model learn complex patterns in the data. The Softmax activation function is used in the output layer because it converts the model’s raw output into probabilities that sum to one. This allows us to interpret the model’s output as the probability of each car manufacturer.</p>
<section id="we-used-the-following-hyperparameters" class="level6">
<h6 class="anchored" data-anchor-id="we-used-the-following-hyperparameters">We used the following hyperparameters:</h6>
<ul>
<li><strong>epochs:</strong> 5 (Corresponds to the number of times the model sees the entire dataset during training.)</li>
<li><strong>batch_size:</strong> 32 (Corresponds to the number of samples that the model processes before updating the weights.)</li>
<li><strong>validation_split:</strong> 0.2 (Corresponds to the fraction of the training data to be used as validation data.)</li>
</ul>
<p>The model is trained for 5 epochs with a batch size of 32. The validation split is set to 0.2, which means that 20% of the training data is used for validation.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions on the test set</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model_no_dropout.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
[1m  1/264[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m2s[0m 8ms/step
[1m218/264[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 231us/step
[1m264/264[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 229us/step</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>y_pred_classes <span class="op">=</span> np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>y_true_classes <span class="op">=</span> np.argmax(y_test, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute confusion matrix</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_true_classes, y_pred_classes)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate specificity and sensitivity for each class</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>tp <span class="op">=</span> np.diag(cm)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>fp <span class="op">=</span> cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>) <span class="op">-</span> np.diag(cm)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>fn <span class="op">=</span> cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> np.diag(cm)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>tn <span class="op">=</span> cm.<span class="bu">sum</span>() <span class="op">-</span> (fp <span class="op">+</span> fn <span class="op">+</span> tp)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Handle potential division by zero</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> np.errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    sensitivity <span class="op">=</span> np.divide(tp, tp <span class="op">+</span> fn)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    specificity <span class="op">=</span> np.divide(tn, tn <span class="op">+</span> fp)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set sensitivities and specificities to 0 where division by zero occurred</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    sensitivity[np.isnan(sensitivity)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    specificity[np.isnan(specificity)] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Print specificity and sensitivity for each class</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>unique_labels <span class="op">=</span> np.unique(y_true_classes)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, class_label <span class="kw">in</span> <span class="bu">enumerate</span>(unique_labels):</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Class </span><span class="sc">{</span>class_label<span class="sc">}</span><span class="ss"> - Sensitivity: </span><span class="sc">{</span>sensitivity[i]<span class="sc">:.4f}</span><span class="ss">, Specificity: </span><span class="sc">{</span>specificity[i]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Class 0 - Sensitivity: 0.0000, Specificity: 1.0000
Class 2 - Sensitivity: 0.6164, Specificity: 0.9981
Class 3 - Sensitivity: 0.5500, Specificity: 0.9999
Class 4 - Sensitivity: 0.2500, Specificity: 1.0000
Class 5 - Sensitivity: 0.7941, Specificity: 0.9999
Class 6 - Sensitivity: 0.7500, Specificity: 0.9939
Class 8 - Sensitivity: 0.0000, Specificity: 1.0000
Class 10 - Sensitivity: 0.9093, Specificity: 0.9841
Class 12 - Sensitivity: 1.0000, Specificity: 1.0000
Class 13 - Sensitivity: 0.9062, Specificity: 1.0000
Class 14 - Sensitivity: 1.0000, Specificity: 1.0000
Class 16 - Sensitivity: 0.0000, Specificity: 1.0000
Class 17 - Sensitivity: 0.5000, Specificity: 0.9998
Class 18 - Sensitivity: 0.5660, Specificity: 0.9977
Class 19 - Sensitivity: 0.6036, Specificity: 0.9382
Class 20 - Sensitivity: 0.3427, Specificity: 0.9934
Class 21 - Sensitivity: 0.0000, Specificity: 1.0000
Class 22 - Sensitivity: 0.0000, Specificity: 1.0000
Class 24 - Sensitivity: 0.0833, Specificity: 0.9996
Class 25 - Sensitivity: 0.0000, Specificity: 1.0000
Class 26 - Sensitivity: 0.6909, Specificity: 0.9727
Class 28 - Sensitivity: 0.0250, Specificity: 1.0000
Class 30 - Sensitivity: 0.0000, Specificity: 1.0000
Class 32 - Sensitivity: 0.0000, Specificity: 0.9998
Class 33 - Sensitivity: 1.0000, Specificity: 0.9994
Class 34 - Sensitivity: 0.8000, Specificity: 1.0000
Class 36 - Sensitivity: 0.7798, Specificity: 0.9611
Class 37 - Sensitivity: 0.2831, Specificity: 0.9755
Class 38 - Sensitivity: 0.0000, Specificity: 1.0000
Class 39 - Sensitivity: 0.5217, Specificity: 0.9998
Class 40 - Sensitivity: 0.3667, Specificity: 0.9976
Class 44 - Sensitivity: 0.6725, Specificity: 0.9819
Class 45 - Sensitivity: 0.4000, Specificity: 1.0000
Class 46 - Sensitivity: 0.4031, Specificity: 0.9880
Class 48 - Sensitivity: 0.5000, Specificity: 0.9998
Class 49 - Sensitivity: 0.7576, Specificity: 0.9986
Class 50 - Sensitivity: 0.0000, Specificity: 1.0000
Class 51 - Sensitivity: 0.2093, Specificity: 0.9988
Class 52 - Sensitivity: 0.2857, Specificity: 1.0000
Class 54 - Sensitivity: 0.6311, Specificity: 0.9969
Class 55 - Sensitivity: 0.7240, Specificity: 0.9920
Class 57 - Sensitivity: 1.0000, Specificity: 1.0000
Class 58 - Sensitivity: 0.5028, Specificity: 0.9913
Class 62 - Sensitivity: 0.7857, Specificity: 0.9995
Class 63 - Sensitivity: 0.8551, Specificity: 0.9984
Class 64 - Sensitivity: 0.6718, Specificity: 0.9965
Class 65 - Sensitivity: 0.4026, Specificity: 0.9958
Class 68 - Sensitivity: 0.8182, Specificity: 0.9994
Class 69 - Sensitivity: 0.2500, Specificity: 1.0000
Class 70 - Sensitivity: 0.9574, Specificity: 0.9989
Class 71 - Sensitivity: 0.0000, Specificity: 1.0000
Class 72 - Sensitivity: 0.8810, Specificity: 0.9996
Class 73 - Sensitivity: 1.0000, Specificity: 0.9999
Class 74 - Sensitivity: 0.5484, Specificity: 0.9896
Class 75 - Sensitivity: 0.8000, Specificity: 1.0000
Class 76 - Sensitivity: 0.0000, Specificity: 1.0000
Class 77 - Sensitivity: 0.9286, Specificity: 0.9967
Class 78 - Sensitivity: 0.0000, Specificity: 0.9998
Class 79 - Sensitivity: 0.5116, Specificity: 0.9841
Class 80 - Sensitivity: 1.0000, Specificity: 1.0000
Class 81 - Sensitivity: 0.0000, Specificity: 1.0000
Class 82 - Sensitivity: 0.6946, Specificity: 0.9823
Class 83 - Sensitivity: 0.0000, Specificity: 1.0000
Class 85 - Sensitivity: 0.0000, Specificity: 0.9996
Class 87 - Sensitivity: 1.0000, Specificity: 0.9996
Class 88 - Sensitivity: 0.0000, Specificity: 1.0000
Class 89 - Sensitivity: 1.0000, Specificity: 1.0000
Class 90 - Sensitivity: 0.1845, Specificity: 0.9929
Class 91 - Sensitivity: 0.0000, Specificity: 1.0000
Class 95 - Sensitivity: 0.9556, Specificity: 0.9973
Class 97 - Sensitivity: 0.9130, Specificity: 0.9994
Class 98 - Sensitivity: 0.0000, Specificity: 0.9998
Class 99 - Sensitivity: 1.0000, Specificity: 0.9995
Class 102 - Sensitivity: 1.0000, Specificity: 0.9999
Class 104 - Sensitivity: 1.0000, Specificity: 0.9994
Class 105 - Sensitivity: 0.0000, Specificity: 1.0000
Class 106 - Sensitivity: 0.6901, Specificity: 0.9952
Class 107 - Sensitivity: 1.0000, Specificity: 1.0000
Class 108 - Sensitivity: 0.0000, Specificity: 1.0000
Class 110 - Sensitivity: 0.6250, Specificity: 0.9980
Class 111 - Sensitivity: 0.3636, Specificity: 0.9993
Class 112 - Sensitivity: 1.0000, Specificity: 1.0000
Class 114 - Sensitivity: 0.7500, Specificity: 1.0000
Class 115 - Sensitivity: 0.9206, Specificity: 0.9897
Class 117 - Sensitivity: 0.4900, Specificity: 0.9941
Class 118 - Sensitivity: 0.5000, Specificity: 1.0000
Class 119 - Sensitivity: 1.0000, Specificity: 0.9992
Class 121 - Sensitivity: 0.0000, Specificity: 1.0000
Class 123 - Sensitivity: 0.5602, Specificity: 0.9846
Class 124 - Sensitivity: 1.0000, Specificity: 1.0000
Class 125 - Sensitivity: 0.0000, Specificity: 1.0000
Class 126 - Sensitivity: 0.5649, Specificity: 0.9922
Class 127 - Sensitivity: 0.8976, Specificity: 0.9975
Class 128 - Sensitivity: 0.2500, Specificity: 0.9998</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create boxplots</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [sensitivity, specificity]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>ax.boxplot(data, labels<span class="op">=</span>[<span class="st">"Sensitivity"</span>, <span class="st">"Specificity"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>{'whiskers': [&lt;matplotlib.lines.Line2D object at 0x3507026f0&gt;, &lt;matplotlib.lines.Line2D object at 0x3506ad100&gt;, &lt;matplotlib.lines.Line2D object at 0x33b6ec6e0&gt;, &lt;matplotlib.lines.Line2D object at 0x3507033e0&gt;], 'caps': [&lt;matplotlib.lines.Line2D object at 0x3506ad490&gt;, &lt;matplotlib.lines.Line2D object at 0x3506ad790&gt;, &lt;matplotlib.lines.Line2D object at 0x3506accb0&gt;, &lt;matplotlib.lines.Line2D object at 0x3506ad040&gt;], 'boxes': [&lt;matplotlib.lines.Line2D object at 0x33daadcd0&gt;, &lt;matplotlib.lines.Line2D object at 0x3506adfa0&gt;], 'medians': [&lt;matplotlib.lines.Line2D object at 0x3506ada90&gt;, &lt;matplotlib.lines.Line2D object at 0x3506ae2a0&gt;], 'fliers': [&lt;matplotlib.lines.Line2D object at 0x3506add60&gt;, &lt;matplotlib.lines.Line2D object at 0x3506ae570&gt;], 'means': []}</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Sensitivity and Specificity for Each Class"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Proportion"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>By looking at the boxplot representing the distribution of the sensitivity and specificity for the classes, we see a clear sign of unbalanced classes. The sensitivity and specificity are not consistent across the classes. This is a sign that the model is not performing well on all classes. We will use class weights to address this issue.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create boxplots</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> [sensitivity, specificity]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>ax.boxplot(data, labels<span class="op">=</span>[<span class="st">"Sensitivity"</span>, <span class="st">"Specificity"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>{'whiskers': [&lt;matplotlib.lines.Line2D object at 0x3768fe150&gt;, &lt;matplotlib.lines.Line2D object at 0x3768feb40&gt;, &lt;matplotlib.lines.Line2D object at 0x3768fff20&gt;, &lt;matplotlib.lines.Line2D object at 0x3768fd1f0&gt;], 'caps': [&lt;matplotlib.lines.Line2D object at 0x3768ff050&gt;, &lt;matplotlib.lines.Line2D object at 0x3768ff320&gt;, &lt;matplotlib.lines.Line2D object at 0x3768fe000&gt;, &lt;matplotlib.lines.Line2D object at 0x3768fd610&gt;], 'boxes': [&lt;matplotlib.lines.Line2D object at 0x3506b26c0&gt;, &lt;matplotlib.lines.Line2D object at 0x3768ffbf0&gt;], 'medians': [&lt;matplotlib.lines.Line2D object at 0x3768ff620&gt;, &lt;matplotlib.lines.Line2D object at 0x3768feae0&gt;], 'fliers': [&lt;matplotlib.lines.Line2D object at 0x3768ff920&gt;, &lt;matplotlib.lines.Line2D object at 0x37696c200&gt;], 'means': []}</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Sensitivity and Specificity for Each Class"</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Proportion"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-8-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>As we can see the model performed better with class weights. The sensitivity and specificity are more consistent across the classes. The model is better at generalizing to new data. Let’s now see how the accuracy evolved during the training process with the following plot.</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-9-5.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p>As we can see, at each epoch, the accuracy is increasing and the loss is decreasing. The model is learning from the training data and improving its predictions.</p>
<p>In the end, we have a case of overfitting. The model performs well on the training data but not as well on the testing data. This is an issue because it limits the possibility of generalizing the model to new data.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Final Training Accuracy: 0.6609</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Validation Accuracy: 0.6462</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Accuracy: 0.6250</code></pre>
</div>
</div>
<p>Overall, the performance of the model is still good. However the quality can be improved. To address this issue, we can introduce Dropout layers in the neural network. We will also see if Cross-validation can help to improve the model’s performance later.</p>
</section>
</section>
<section id="neural-network-with-dropout-layers" class="level4">
<h4 class="anchored" data-anchor-id="neural-network-with-dropout-layers">Neural Network with Dropout layers</h4>
<p>Dropout layers randomly set a fraction of input units to zero during training, which helps prevent overfitting by forcing the model to learn more robust features. We will tune the dropout rate to find the optimal value that balances training and validation accuracy and that insure to reduce overfitting.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to create and compile the model</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model(dropout_rate<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential([</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        Input(shape<span class="op">=</span>(X_train.shape[<span class="dv">1</span>],)),</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        Dense(<span class="dv">128</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        Dropout(dropout_rate),</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        Dropout(dropout_rate),</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        Dense(y_train.shape[<span class="dv">1</span>], activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer<span class="op">=</span>Adam(), loss<span class="op">=</span><span class="st">'categorical_crossentropy'</span>, metrics<span class="op">=</span>[<span class="st">'accuracy'</span>])</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-15-7.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p>We can see that the model with a dropout rate of 0.2 has the best performance on the test set. This model has a good balance between training and validation accuracy, and it generalizes well to new data. It also eliminate the overfitting issue. We will use this dropout rate to train the final model with droopout layers.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Out best dropout rate used for the following model.</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>dropout_rate_to_plot <span class="op">=</span> <span class="fl">0.2</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-18-9.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Helper function to calculate metrics from confusion matrix</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_metrics(cm):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># True Positive, False Positive, False Negative, True Negative</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    tp <span class="op">=</span> cm[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    fp <span class="op">=</span> cm[<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    fn <span class="op">=</span> cm[<span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    tn <span class="op">=</span> cm[<span class="dv">0</span>, <span class="dv">0</span>]</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    sensitivity <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn)  <span class="co"># True Positive Rate</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    specificity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fp)  <span class="co"># True Negative Rate</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    balanced_accuracy <span class="op">=</span> (sensitivity <span class="op">+</span> specificity) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sensitivity, specificity, balanced_accuracy</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the dropout rate to use</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>dropout_rate <span class="op">=</span> <span class="fl">0.2</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model with the specified dropout rate</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing model with dropout rate: </span><span class="sc">{</span>dropout_rate<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Testing model with dropout rate: 0.2</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> create_model(dropout_rate<span class="op">=</span>dropout_rate)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model and collect training accuracy</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> model.fit(X_train_split, y_train_split, epochs<span class="op">=</span><span class="dv">5</span>, batch_size<span class="op">=</span><span class="dv">32</span>, verbose<span class="op">=</span><span class="dv">0</span>, validation_data<span class="op">=</span>(X_val, y_val))</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on the validation set</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>val_loss, val_accuracy <span class="op">=</span> model.evaluate(X_val, y_val, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on the test set</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>test_loss, test_accuracy <span class="op">=</span> model.evaluate(X_test, y_test, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Store the last epoch's training accuracy, validation accuracy, and test accuracy</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>training_accuracy <span class="op">=</span> history.history[<span class="st">'accuracy'</span>][<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>training_accuracies <span class="op">=</span> [training_accuracy]</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>validation_accuracies <span class="op">=</span> [val_accuracy]</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>test_accuracies <span class="op">=</span> [test_accuracy]</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Print rounded accuracy values</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training accuracy: </span><span class="sc">{</span><span class="bu">round</span>(training_accuracy, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">, Validation accuracy: </span><span class="sc">{</span><span class="bu">round</span>(val_accuracy, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">, Test accuracy: </span><span class="sc">{</span><span class="bu">round</span>(test_accuracy, <span class="dv">2</span>)<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Training accuracy: 0.56, Validation accuracy: 0.62, Test accuracy: 0.6</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate the confusion matrix and metrics</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.argmax(model.predict(X_test), axis<span class="op">=-</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
[1m  1/264[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m5s[0m 19ms/step
[1m214/264[0m [32m━━━━━━━━━━━━━━━━[0m[37m━━━━[0m [1m0s[0m 236us/step
[1m264/264[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 233us/step</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> np.argmax(y_test, axis<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_true, y_pred)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert confusion matrix to a DataFrame for better readability</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>cm_df <span class="op">=</span> pd.DataFrame(cm, index<span class="op">=</span>[<span class="ss">f'Actual </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">0</span>])],</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                     columns<span class="op">=</span>[<span class="ss">f'Predicted </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(cm.shape[<span class="dv">1</span>])])</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the confusion matrix as a table</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Confusion Matrix for Dropout Rate </span><span class="sc">{</span>dropout_rate<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Confusion Matrix for Dropout Rate 0.2</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cm_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>           Predicted 0  Predicted 1  ...  Predicted 92  Predicted 93
Actual 0             0            0  ...             0             0
Actual 1             0           41  ...             0             0
Actual 2             0            0  ...             0             0
Actual 3             0            0  ...             0             0
Actual 4             0            0  ...             0             0
...                ...          ...  ...           ...           ...
Actual 89            0            0  ...             0             0
Actual 90            0            0  ...             0             0
Actual 91            0            0  ...             0             0
Actual 92            0            0  ...             0             0
Actual 93            0            0  ...             0             9

[94 rows x 94 columns]</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate and print sensitivity, specificity, and balanced accuracy</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>sensitivity, specificity, balanced_accuracy <span class="op">=</span> calculate_metrics(cm)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;string&gt;:10: RuntimeWarning: invalid value encountered in scalar divide</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sensitivity: </span><span class="sc">{</span>sensitivity<span class="sc">:.2f}</span><span class="ss">, Specificity: </span><span class="sc">{</span>specificity<span class="sc">:.2f}</span><span class="ss">, Balanced Accuracy: </span><span class="sc">{</span>balanced_accuracy<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Sensitivity: 1.00, Specificity: nan, Balanced Accuracy: nan</code></pre>
</div>
</div>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate predictions on the test set</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>
[1m  1/264[0m [37m━━━━━━━━━━━━━━━━━━━━[0m [1m1s[0m 7ms/step
[1m227/264[0m [32m━━━━━━━━━━━━━━━━━[0m[37m━━━[0m [1m0s[0m 222us/step
[1m264/264[0m [32m━━━━━━━━━━━━━━━━━━━━[0m[37m[0m [1m0s[0m 221us/step</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>y_pred_classes <span class="op">=</span> np.argmax(y_pred, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>y_true_classes <span class="op">=</span> np.argmax(y_test, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute confusion matrix</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>cm <span class="op">=</span> confusion_matrix(y_true_classes, y_pred_classes)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the confusion matrix</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>disp <span class="op">=</span> ConfusionMatrixDisplay(confusion_matrix<span class="op">=</span>cm, display_labels<span class="op">=</span>np.unique(y_true_classes))</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>disp.plot(cmap<span class="op">=</span>plt.cm.Blues)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x37730fb60&gt;</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Confusion Matrix'</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-20-11.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate specificity and sensitivity for each class</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>tp <span class="op">=</span> np.diag(cm)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>fp <span class="op">=</span> cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>) <span class="op">-</span> np.diag(cm)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>fn <span class="op">=</span> cm.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> np.diag(cm)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>tn <span class="op">=</span> cm.<span class="bu">sum</span>() <span class="op">-</span> (fp <span class="op">+</span> fn <span class="op">+</span> tp)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>sensitivity <span class="op">=</span> tp <span class="op">/</span> (tp <span class="op">+</span> fn)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>specificity <span class="op">=</span> tn <span class="op">/</span> (tn <span class="op">+</span> fp)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Print specificity and sensitivity for each class</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>unique_labels <span class="op">=</span> np.unique(y_true_classes)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, class_label <span class="kw">in</span> <span class="bu">enumerate</span>(unique_labels):</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Class </span><span class="sc">{</span>class_label<span class="sc">}</span><span class="ss"> - Sensitivity: </span><span class="sc">{</span>sensitivity[i]<span class="sc">:.4f}</span><span class="ss">, Specificity: </span><span class="sc">{</span>specificity[i]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Class 0 - Sensitivity: 0.0000, Specificity: 1.0000
Class 2 - Sensitivity: 0.5616, Specificity: 0.9987
Class 3 - Sensitivity: 0.1500, Specificity: 0.9999
Class 4 - Sensitivity: 0.0000, Specificity: 1.0000
Class 5 - Sensitivity: 0.7647, Specificity: 0.9996
Class 6 - Sensitivity: 0.5381, Specificity: 0.9965
Class 8 - Sensitivity: 0.0000, Specificity: 1.0000
Class 10 - Sensitivity: 0.8960, Specificity: 0.9761
Class 12 - Sensitivity: 0.0000, Specificity: 1.0000
Class 13 - Sensitivity: 0.5625, Specificity: 0.9994
Class 14 - Sensitivity: 1.0000, Specificity: 1.0000
Class 16 - Sensitivity: 0.0000, Specificity: 1.0000
Class 17 - Sensitivity: 0.0000, Specificity: 1.0000
Class 18 - Sensitivity: 0.4528, Specificity: 0.9981
Class 19 - Sensitivity: 0.6663, Specificity: 0.9274
Class 20 - Sensitivity: 0.3357, Specificity: 0.9921
Class 21 - Sensitivity: 0.0000, Specificity: 1.0000
Class 22 - Sensitivity: 0.0000, Specificity: 1.0000
Class 24 - Sensitivity: 0.0000, Specificity: 0.9999
Class 25 - Sensitivity: 0.0000, Specificity: 1.0000
Class 26 - Sensitivity: 0.6555, Specificity: 0.9743
Class 28 - Sensitivity: 0.0000, Specificity: 1.0000
Class 30 - Sensitivity: 0.0000, Specificity: 1.0000
Class 32 - Sensitivity: 0.0000, Specificity: 1.0000
Class 33 - Sensitivity: 1.0000, Specificity: 0.9983
Class 34 - Sensitivity: 0.7000, Specificity: 1.0000
Class 36 - Sensitivity: 0.7812, Specificity: 0.9484
Class 37 - Sensitivity: 0.0819, Specificity: 0.9912
Class 38 - Sensitivity: 0.0000, Specificity: 1.0000
Class 39 - Sensitivity: 0.6522, Specificity: 0.9996
Class 40 - Sensitivity: 0.5333, Specificity: 0.9964
Class 44 - Sensitivity: 0.4279, Specificity: 0.9932
Class 45 - Sensitivity: 0.0000, Specificity: 1.0000
Class 46 - Sensitivity: 0.4817, Specificity: 0.9789
Class 48 - Sensitivity: 0.0000, Specificity: 1.0000
Class 49 - Sensitivity: 0.7273, Specificity: 0.9981
Class 50 - Sensitivity: 0.0000, Specificity: 1.0000
Class 51 - Sensitivity: 0.3953, Specificity: 0.9956
Class 52 - Sensitivity: 0.2857, Specificity: 1.0000
Class 54 - Sensitivity: 0.4754, Specificity: 0.9971
Class 55 - Sensitivity: 0.7865, Specificity: 0.9890
Class 57 - Sensitivity: 0.0000, Specificity: 1.0000
Class 58 - Sensitivity: 0.2570, Specificity: 0.9955
Class 62 - Sensitivity: 0.8571, Specificity: 0.9989
Class 63 - Sensitivity: 0.7971, Specificity: 0.9983
Class 64 - Sensitivity: 0.4427, Specificity: 0.9976
Class 65 - Sensitivity: 0.2987, Specificity: 0.9978
Class 68 - Sensitivity: 0.6364, Specificity: 0.9995
Class 69 - Sensitivity: 0.0000, Specificity: 1.0000
Class 70 - Sensitivity: 0.9149, Specificity: 0.9960
Class 71 - Sensitivity: 0.0000, Specificity: 1.0000
Class 72 - Sensitivity: 0.7143, Specificity: 0.9983
Class 73 - Sensitivity: 0.5000, Specificity: 1.0000
Class 74 - Sensitivity: 0.4147, Specificity: 0.9909
Class 75 - Sensitivity: 0.5333, Specificity: 1.0000
Class 76 - Sensitivity: 0.0000, Specificity: 1.0000
Class 77 - Sensitivity: 0.9343, Specificity: 0.9900
Class 78 - Sensitivity: 0.0000, Specificity: 1.0000
Class 79 - Sensitivity: 0.5721, Specificity: 0.9796
Class 80 - Sensitivity: 0.0000, Specificity: 1.0000
Class 81 - Sensitivity: 0.0000, Specificity: 1.0000
Class 82 - Sensitivity: 0.4631, Specificity: 0.9871
Class 83 - Sensitivity: 0.0000, Specificity: 1.0000
Class 85 - Sensitivity: 0.0000, Specificity: 1.0000
Class 87 - Sensitivity: 0.0000, Specificity: 1.0000
Class 88 - Sensitivity: 0.0000, Specificity: 1.0000
Class 89 - Sensitivity: 0.0971, Specificity: 0.9972
Class 90 - Sensitivity: 0.0000, Specificity: 1.0000
Class 91 - Sensitivity: 0.9519, Specificity: 0.9897
Class 95 - Sensitivity: 1.0000, Specificity: 0.9994
Class 97 - Sensitivity: 0.0000, Specificity: 1.0000
Class 98 - Sensitivity: 0.9744, Specificity: 0.9990
Class 99 - Sensitivity: 0.4737, Specificity: 0.9995
Class 102 - Sensitivity: 0.0000, Specificity: 1.0000
Class 104 - Sensitivity: 0.4930, Specificity: 0.9971
Class 105 - Sensitivity: 0.0000, Specificity: 1.0000
Class 106 - Sensitivity: 0.0000, Specificity: 1.0000
Class 107 - Sensitivity: 0.4792, Specificity: 0.9987
Class 108 - Sensitivity: 0.0000, Specificity: 1.0000
Class 110 - Sensitivity: 0.0000, Specificity: 1.0000
Class 111 - Sensitivity: 0.0000, Specificity: 1.0000
Class 112 - Sensitivity: 0.8624, Specificity: 0.9910
Class 114 - Sensitivity: 0.4200, Specificity: 0.9922
Class 115 - Sensitivity: 0.0000, Specificity: 1.0000
Class 117 - Sensitivity: 1.0000, Specificity: 0.9975
Class 118 - Sensitivity: 0.0000, Specificity: 1.0000
Class 119 - Sensitivity: 0.6390, Specificity: 0.9564
Class 121 - Sensitivity: 0.0000, Specificity: 1.0000
Class 123 - Sensitivity: 0.0000, Specificity: 1.0000
Class 124 - Sensitivity: 0.6221, Specificity: 0.9873
Class 125 - Sensitivity: 0.7831, Specificity: 0.9967
Class 126 - Sensitivity: 0.2500, Specificity: 1.0000
Class 127 - Sensitivity: 0.0000, Specificity: 1.0000
Class 128 - Sensitivity: 1.0000, Specificity: 0.9999</code></pre>
</div>
</div>
<p>The model is trained using the training data. During training, the model learns by adjusting its internal parameters to minimize the difference between its predictions and the actual car manufacturers in the training data. The model is trained for a fixed number of iterations called epochs.</p>
</section>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>