<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>results_neural_network</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="results_neural_network_files/libs/clipboard/clipboard.min.js"></script>
<script src="results_neural_network_files/libs/quarto-html/quarto.js"></script>
<script src="results_neural_network_files/libs/quarto-html/popper.min.js"></script>
<script src="results_neural_network_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="results_neural_network_files/libs/quarto-html/anchor.min.js"></script>
<link href="results_neural_network_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="results_neural_network_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="results_neural_network_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="results_neural_network_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="results_neural_network_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<section id="neural-networks" class="level1">
<h1>Neural Networks</h1>
<p>In this section, we will build a neural network model to predict the make of a car based on the features at our disposal. We will preprocess the data, split it into training and testing sets, define the neural network architecture, compile the model, train it and evaluate its performance.</p>
<section id="preprocessing-and-splitting-the-data" class="level2">
<h2 class="anchored" data-anchor-id="preprocessing-and-splitting-the-data">Preprocessing and splitting the data</h2>
<p>The dataset contains different types of data. Some columns are numerical (like “city_mpg_fuel_type_1” or “charge_time_240v”), and some are categorical (“vehicle_class” or “fuel_type”). We identify and differentiate these two types of columns, subsequently preprocessing them accordingly.</p>
<p>The data is split into a training set and a testing set. The training set is used to train the model, and the testing set is used to evaluate its performance. This split ensures that we can test how well the model generalizes to new, unseen data.</p>
<section id="building-the-neural-network-models-and-training-them" class="level3">
<h3 class="anchored" data-anchor-id="building-the-neural-network-models-and-training-them">Building the neural network models and training them</h3>
<section id="base-neural-network" class="level4">
<h4 class="anchored" data-anchor-id="base-neural-network">Base Neural Network</h4>
<p>We chose to use a neural network. This neural network consists of layers of neurons, where each layer applies transformations to the data. The first layer takes the input features. Then some Hidden layers help the model learn complex patterns. In the end, the output layer predicts the probability of each car manufacturer. The first layer, the input layer, takes the preprocessed input features. The second layer is set to 128 neurons, the third to 64 neurons and the last layer, the output layer, has as many neurons as there are car manufacturers (66 in our case). The activation function used in the hidden layers is the Rectified Linear Unit (ReLU), and the output layer uses the Softmax activation function. The model is compiled with the Adam optimizer and the categorical cross-entropy loss function.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Base neural network model</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>model_base <span class="op">=</span> Sequential([</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    Input(shape <span class="op">=</span> (X_train.shape[<span class="dv">1</span>],)),</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">128</span>, activation <span class="op">=</span> <span class="st">'relu'</span>),</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">64</span>, activation <span class="op">=</span> <span class="st">'relu'</span>),</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    Dense(y_train.shape[<span class="dv">1</span>], activation <span class="op">=</span> <span class="st">'softmax'</span>)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We used activation functions in the hidden layers to introduce non-linearity into the model. The ReLU activation function is used in the hidden layers because it is computationally efficient and helps the model learn complex patterns in the data. The Softmax activation function is used in the output layer because it converts the model’s raw output into probabilities that sum to one. This allows us to interpret the model’s output as the probability of each car manufacturer.</p>
<section id="we-used-the-following-hyperparameters-for-the-base-model-non-exhaustive-list" class="level7">
<p class="heading">We used the following hyperparameters for the base model (non-exhaustive list):</p>
<ul>
<li><strong>epochs:</strong> 150 (Corresponds to the number of times the model sees the entire dataset during training.)</li>
<li><strong>batch_size:</strong> 32 (Corresponds to the number of samples that the model processes before updating the weights.)</li>
<li><strong>validation_split:</strong> 0.2 (Corresponds to the fraction of the training data to be used as validation data.)</li>
</ul>
<p>The model is trained for 5 epochs with a batch size of 32. The validation split is set to 0.2, which means that 20% of the training data is kept to be used as a validation set.</p>
<p>Overall, the model perform well but we have’t dealt with the issue of unbalanced classes yet. Let’s have a look at the distribution of the sensitivity and specificity for each class.</p>
</section>
<section id="issue-of-unbalanced-classes" class="level5">
<h5 class="anchored" data-anchor-id="issue-of-unbalanced-classes">Issue of unbalanced classes</h5>
<p>The isse of unbalanced classes, as explained previously can highly weaken the model ability to generalize to new data. The model, will automatically prefer to predict the most frequent classes. We can see in the boxplots below the distribution of the sensitivity and specificity for the classes. Even though, we already dealt in part with the unbalanced class during the cleaning process, as seen in the plot in section <strong>?@sec-make_n_plot</strong>, there’s still big differences between the classes.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>{'whiskers': [&lt;matplotlib.lines.Line2D object at 0x2ba4d92b0&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4d97c0&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4db560&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4db140&gt;], 'caps': [&lt;matplotlib.lines.Line2D object at 0x2ba4d9c40&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4da240&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4da8d0&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4dae40&gt;], 'boxes': [&lt;matplotlib.lines.Line2D object at 0x2a8b82cf0&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4d9460&gt;], 'medians': [&lt;matplotlib.lines.Line2D object at 0x2ba4da480&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4da810&gt;], 'fliers': [&lt;matplotlib.lines.Line2D object at 0x2ba4da450&gt;, &lt;matplotlib.lines.Line2D object at 0x2ba4db920&gt;], 'means': []}</code></pre>
</div>
<div class="cell-output-display">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>By examining the boxplot representing the distribution of sensitivity and specificity across the classes, we observe clear evidence of class imbalance. Sensitivity and specificity are not consistent across the classes. Specificity, which measures how well the model identifies true negatives, is very high for every class. This indicates that the model is effective at detecting instances that do not belong to a given class. However, sensitivity, which measures the true positive rate and reflects how well the model correctly predicts the make of a car for a specific brand, is not as high. This suggests that the model is not performing well for all classes.</p>
<p>For some classes with more vehicle models, the model tends to predict those classes more frequently, leading to higher accuracy but lower sensitivity for rarer classes. To address this issue, we will use class weights to ensure the model performs more evenly across all classes.</p>
</section>
<section id="adding-class-weights-to-the-model" class="level5">
<h5 class="anchored" data-anchor-id="adding-class-weights-to-the-model">Adding class weights to the model</h5>
<p>This technique, detailed in the methods section, essentially penalizes the model more for misclassifying the minority class than the majority class. By doing so, the model is encouraged to learn the patterns of the minority class more effectively, thereby enhancing its performance on the test set.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>{'whiskers': [&lt;matplotlib.lines.Line2D object at 0x2bc1c1820&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c1af0&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c3680&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c0650&gt;], 'caps': [&lt;matplotlib.lines.Line2D object at 0x2bc1c1d30&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c2060&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c0530&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c2360&gt;], 'boxes': [&lt;matplotlib.lines.Line2D object at 0x2bc1c1520&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c3380&gt;], 'medians': [&lt;matplotlib.lines.Line2D object at 0x2bc1c0b60&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c28d0&gt;], 'fliers': [&lt;matplotlib.lines.Line2D object at 0x2bc1c30e0&gt;, &lt;matplotlib.lines.Line2D object at 0x2bc1c3890&gt;], 'means': []}</code></pre>
</div>
<div class="cell-output-display">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-11-3.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>As we can see the model is taking better care of the minority classes and overall the sensitivity is higher across the classes. The sensitivity and specificity are more consistent across the classes. The model is better at generalizing to new data. In our case, this method does not eliminate completely the issue of unbalanced classes. Given the structure of our data and the discrepancy of our classes, we will use this technique for the following neural networks and move on.</p>
</section>
<section id="model-performance" class="level5">
<h5 class="anchored" data-anchor-id="model-performance">Model performance</h5>
<p>We can now look at the evolution of the accuracy of our model during the training process with the following plot.</p>
<div class="cell">
<div class="cell-output-display">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-12-5.png" class="img-fluid" width="960"></p>
</div>
</div>
<p>As we can see, at each epoch, the accuracy is increasing and the loss is decreasing. The model is learning from the training data and improving its predictions.</p>
<p>But, in the end, we have a case of overfitting. The model performs well on the training data but not as well on the testing data. This is an issue because it limits the possibility of generalizing the model to new data.</p>
<p><strong>Performance of the model with weighted class:</strong></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Final Training Accuracy: 23.32%</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Validation Accuracy: 34.83%</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Set Accuracy: 34.58%</code></pre>
</div>
</div>
<p>Overall, the performance of the model is still good. However the quality can be improved. To address the issue of overfitting, we will introduce Dropout layers in the neural network.</p>
</section>
</section>
<section id="neural-network-with-dropout-layers" class="level4">
<h4 class="anchored" data-anchor-id="neural-network-with-dropout-layers">Neural Network with Dropout layers</h4>
<p>Dropout layers randomly set a fraction of neurons to zero during training, which helps prevent overfitting by forcing the model to learn more robust features. We will tune the dropout rates to find the optimal value that balances training and validation accuracy and that insure to reduce overfitting.</p>
<section id="we-used-the-following-hyperparameters-non-exhaustive-list" class="level7">
<p class="heading">We used the following hyperparameters (non-exhaustive list):</p>
<ul>
<li><strong>epochs:</strong> 150 (Corresponds to the number of times the model sees the entire dataset during training.)</li>
<li><strong>batch_size:</strong> 32 (Corresponds to the number of samples that the model processes before updating the weights.)</li>
<li><strong>validation_split:</strong> 0.2 (Corresponds to the fraction of the training data to be used as validation data.)</li>
<li><strong>dropout_rate:</strong> varies (Corresponds to the fraction of neurons to drop during training.)</li>
</ul>
<p>We will try 5 different dropout rates in addition of the case of no dropout. We will train the model with each dropout rate and evaluate its performance on the validation and test sets. We will then plot the training, validation, and test accuracies for each dropout rate to find the optimal value.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Model with Dropout layers</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_model(dropout_rate <span class="op">=</span> <span class="fl">0.0</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> Sequential([</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        Input(shape <span class="op">=</span> (X_train.shape[<span class="dv">1</span>],)),</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        Dense(<span class="dv">128</span>, activation <span class="op">=</span> <span class="st">'relu'</span>),</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        Dropout(dropout_rate),</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        Dense(<span class="dv">64</span>, activation <span class="op">=</span> <span class="st">'relu'</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        Dropout(dropout_rate),</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        Dense(y_train.shape[<span class="dv">1</span>], activation <span class="op">=</span> <span class="st">'softmax'</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">compile</span>(optimizer <span class="op">=</span> Adam(), loss <span class="op">=</span> <span class="st">'categorical_crossentropy'</span>, metrics <span class="op">=</span> [<span class="st">'accuracy'</span>])</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="selection-of-the-best-dropout-rate" class="level5">
<h5 class="anchored" data-anchor-id="selection-of-the-best-dropout-rate">Selection of the best dropout rate</h5>
<div class="cell">
<div class="cell-output-display">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-18-7.png" class="img-fluid" width="960"></p>
</div>
</div>
<p>We can see that the model with a dropout rate of 0.1 has the best balance between reducing drastically the overfitting problem and keeping a good overall accuracy. This model has a good balance between training and validation accuracy, and it generalizes well to new data. It also eliminate the overfitting issue. We will use this dropout rate of 0.1 to train the final model that utilize class weights and dropout layers.</p>
</section>
<section id="model-performance-1" class="level5">
<h5 class="anchored" data-anchor-id="model-performance-1">Model performance</h5>
<div class="cell">
<div class="cell-output-display">
<p><img src="results_neural_network_files/figure-html/unnamed-chunk-21-9.png" class="img-fluid" width="960"></p>
</div>
</div>
<p>We see that the model with dropout layers performs better that the one without it. We reached a better accuracy on the validation set and the model is clearly not overfitting as much. It is interesting to note that the validation accuracy is higher than the training accuracy. This is a good sign that the model is generalizing well to new data. It is also interesting to note that, as predicted, we see that the validation accuracy is higher than the training accuracy. This is due to the way dropout layers work. The model does not need early stopping in our case (150 epochs) since the accuracies are not deacreasing and the loss is not increasing.</p>
<p><strong>Performance of the model with weighted class and dropout layers:</strong></p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Final Training Accuracy: 20.21%</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Final Validation Accuracy: 33.39%</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Set Accuracy: 32.77%</code></pre>
</div>
</div>
<p>Our final accuracy of our model are not as great as we had with our first model but the model that we are using is at least better at representing the data and generalizing to new data. We aslo computed the Cohen’s Kappa score which is a good indicator of the model’s performance. And as we can see, the model performs well.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Cohen's Kappa Score: 31.73%</code></pre>
</div>
</div>
</section>
</section>
</section>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>