{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "---"
      ],
      "id": "0956a8cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test\n"
      ],
      "id": "8b6956ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyprojroot.here import here\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(here(\"data/data_cleaned.csv\"))\n",
        "\n",
        "# Display the structure of the data\n",
        "print(data.info())\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(data.head())\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Remove the target column 'make' from the features list\n",
        "if 'make' in categorical_cols:\n",
        "    categorical_cols.remove('make')\n",
        "if 'make' in numerical_cols:\n",
        "    numerical_cols.remove('make')\n",
        "\n",
        "print(f\"Categorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")\n",
        "\n",
        "# Define the preprocessing steps for numerical and categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(sparse_output=False), categorical_cols)  # Set sparse_output to False\n",
        "    ])\n",
        "\n",
        "# Split data into features and target\n",
        "X = data.drop('make', axis=1)\n",
        "y = data['make']\n",
        "\n",
        "# Apply preprocessing and split data into training and testing sets\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Encode the target variable\n",
        "y_encoded = pd.get_dummies(y).values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_encoded, test_size=0.2, random_state=123)\n",
        "\n",
        "# Define the neural network model\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(y_train.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "# Print predictions\n",
        "print(predictions)\n",
        "\n",
        "# Plot the accuracy and loss\n",
        "fig, axs = plt.subplots(2, 1, figsize=(10, 10))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "axs[0].plot(history.history['accuracy'])\n",
        "axs[0].plot(history.history['val_accuracy'])\n",
        "axs[0].set_title('Model accuracy')\n",
        "axs[0].set_ylabel('Accuracy')\n",
        "axs[0].set_xlabel('Epoch')\n",
        "axs[0].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "axs[1].plot(history.history['loss'])\n",
        "axs[1].plot(history.history['val_loss'])\n",
        "axs[1].set_title('Model loss')\n",
        "axs[1].set_ylabel('Loss')\n",
        "axs[1].set_xlabel('Epoch')\n",
        "axs[1].legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "098d6021",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}