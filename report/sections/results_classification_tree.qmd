---
format:
  html:
    code-fold: true
---

# Classification Tree

After loading the necessary packages, the dataset and then prepared it, here are the results of our Classification Tree models. 

### Loading R packages, Python libraries and Data Preparation
```{r Loading R packages CT, echo= FALSE, message = FALSE, output = FALSE}
source(here::here("scripts","setup.R"))
```

```{python Loading python Librairies CT, echo = FALSE, message = FALSE, waring = FALSE, output = FALSE}
import subprocess
subprocess.run(['pip3', 'install', "pyprojroot"], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
from pyprojroot.here import here
open(here("scripts/setup.py"))
```

```{python Importing necessayry functions and the data, echo = FALSE, message = FALSE}
# !pip3 install pyprojroot ----- TO INSTALL IF MISSING
import pandas as pd
from sklearn.model_selection import train_test_split, KFold, cross_val_score
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score
from sklearn.preprocessing import LabelEncoder
# !pip install matplotlib seaborn ------- INSTALL IF NEEDED
import matplotlib.pyplot as plt
import seaborn as sns
from pyprojroot.here import here
# !pip install matplotlib seaborn scikit-learn ------- INSTALL IF NEEDED

# Load the dataset
file_path = here("data/data_cleaned_reduced.csv")
data = pd.read_csv(file_path)
```

```{python Preparing the data, echo = FALSE}

# Preprocess the data
# Assuming 'make' is the target variable and all other columns are features
target = 'make'
features = data.columns.drop(target)

# Encode categorical variables
label_encoders = {}
for column in data.columns:
    if data[column].dtype == 'object':
        le = LabelEncoder()
        data[column] = le.fit_transform(data[column])
        label_encoders[column] = le
```

After importing the necessary libraries and imported our dataset, we splitted it into training (80%) and testing (20%). This step is essential for preventing overfitting, try to select the best model configuration by training the model, then assess the final model performance on our "unseen data" of the testing set. This helps to build a robust model that generalizes well to new data. Unfortunately, we will see later that our model is overfitting, meaning that it performs poorly when seeing new data. We will address this issue later. You will find here an plot showing the actual data splitting effectuated. The x axis represent the number of observations in our dataset and the y axis the number of makes. 

```{python Splitting the data, echo = FALSE}
# Split the data into training and testing sets
X = data[features]
y = data[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

```{python, echo = FALSE}

# Combine the train and test data for visualization
train_data = X_train.copy()
train_data[target] = y_train
train_data['Set'] = 'Train'

test_data = X_test.copy()
test_data[target] = y_test
test_data['Set'] = 'Test'

combined_data = pd.concat([train_data, test_data])

# Visualize the data split
plt.figure(figsize=(10, 6))
sns.scatterplot(data=combined_data, x=combined_data.index, y=target, hue='Set', palette=['blue', 'orange'])
plt.title('Visualization of Training and Testing Data Split')
plt.xlabel('Data Index')
plt.ylabel('Target Variable (make)')
plt.legend(title='Dataset')
plt.show()

```

### Training the Decision Tree without Pruning - Results

Starting to train our Decision Tree, we have first decided to do it without any constraints and see the results of it. 

```{python, echo = FALSE}

# Train the Decision Tree without specifying max_depth
clf_no_prune = DecisionTreeClassifier(random_state=42)
clf_no_prune.fit(X_train, y_train)

# Predict and calculate accuracies
y_pred_train_no_prune = clf_no_prune.predict(X_train)
y_pred_test_no_prune = clf_no_prune.predict(X_test)
accuracy_train_no_prune = accuracy_score(y_train, y_pred_train_no_prune)
accuracy_test_no_prune = accuracy_score(y_test, y_pred_test_no_prune)
kappa_train_no_prune = cohen_kappa_score(y_train, y_pred_train_no_prune)
kappa_test_no_prune = cohen_kappa_score(y_test, y_pred_test_no_prune)

print(f"Training Accuracy (without max_depth): {accuracy_train_no_prune:.4f}")
print(f"Test Accuracy (without max_depth): {accuracy_test_no_prune:.4f}")
print(f"Test Cohen's Kappa (without max_depth): {kappa_test_no_prune:.4f}")

# Visualize the Decision Tree without pruning
# plt.figure(figsize=(20, 10))
# plot_tree(clf_no_prune, filled=True, feature_names=features, class_names=label_encoders[target].classes_)
# plt.title("Decision Tree (without max_depth)")
# plt.show()
```

As we can see, the tree resulting from our training is much complex, takes a lot of time to train and is not interpretable at all. Also, we can see that the accuracy of the training set is higher than both the observed accuracy and cohen's kappa of the test set, attesting that our model is overfitting. 

### Training the Decision Tree with K-fold cross-validation - Results

In order to assess the performance of the model, we also tried to use a K-fold cross-validation with 10 folds. 

```{python}

# Initialize the classifier
clf = DecisionTreeClassifier(random_state=42)

# Initialize KFold cross-validator
kf = KFold(n_splits=10, shuffle=True, random_state=42)

# Perform k-fold cross-validation
cv_scores = cross_val_score(clf, X, y, cv=kf, scoring='accuracy')

# Print the cross-validation scores
print("Cross-validation scores: ", cv_scores)
print("Mean cross-validation score: ", cv_scores.mean())

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the classifier on the training set
clf.fit(X_train, y_train)

# Predict on the training set and test set
y_train_pred = clf.predict(X_train)
y_test_pred = clf.predict(X_test)

# Calculate the training and test set accuracies
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"Training set accuracy: {train_accuracy:.4f}")
print(f"Test set accuracy: {test_accuracy:.4f}")

# Visualize the decision tree
from sklearn.tree import plot_tree

# plt.figure(figsize=(20, 10))
# plot_tree(clf, filled=True, feature_names=features, class_names=label_encoders[target].classes_)
# plt.title('Decision Tree')
# plt.show()
```

With a number of fold of 10, we have not been able to fight overfitting, as the training accuracy remaines higher than the test accuracy, but we notice that our mean accuracy is approx. 70%, which is quite good. nevertheless, we need to address overfitting. 

### Training the Decision Tree with Pruning method - Results

Then, we have decided to prune our tree and then train it to have a less complex tree and to fight overfittingness. We set different max_depth parameter values to control the tree's growth (5, 10, 15, 20, 25, 30). We want here to find the optimal tree depth that balances between training and test accuracy. for visibility reasons, we have decided to represent a classification tree with only 5 max_depth. "None" is actually the training without any max_depth parameter. Here are our new results: 

```{python, echo = FALSE}
# Define a function to train and evaluate the Decision Tree with different max_depth values
def train_and_evaluate_tree(max_depth):
    clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)
    clf.fit(X_train, y_train)
    y_pred_train = clf.predict(X_train)
    y_pred_test = clf.predict(X_test)
    accuracy_train = accuracy_score(y_train, y_pred_train)
    accuracy_test = accuracy_score(y_test, y_pred_test)
    kappa_train = cohen_kappa_score(y_train, y_pred_train)
    kappa_test = cohen_kappa_score(y_test, y_pred_test)
    return clf, accuracy_train, accuracy_test, kappa_train, kappa_test

# Evaluate the model with different max_depth values
max_depth_values = [5, 10, 15, 20, 25, 30]
results = {}
clfs = {}

for depth in max_depth_values:
    clf, accuracy_train, accuracy_test, kappa_train, kappa_test = train_and_evaluate_tree(depth)
    results[depth] = {
        "Train Accuracy": accuracy_train,
        "Test Accuracy": accuracy_test,
        "Test Cohen's Kappa": kappa_test
    }
    clfs[depth] = clf  # Store the classifier for visualization

# Convert results to a DataFrame for better visualization
results_df = pd.DataFrame.from_dict(results, orient='index')

# Print the DataFrame
print(results_df)

# Extract test accuracies to find the best depth
test_scores = results_df["Test Accuracy"].tolist()

# Extract feature importances
# Extract feature importances from the best tree (based on test accuracy)
best_depth = max_depth_values[test_scores.index(max(test_scores))]
best_clf = clfs[best_depth]

# Assuming 'features' is a list of feature names
feature_importances = best_clf.feature_importances_

# Create a DataFrame for easy visualization
importances_df = pd.DataFrame({
    'Feature': features,
    'Importance': feature_importances
})

# Sort the DataFrame by feature importance in descending order
importances_df = importances_df.sort_values(by='Importance', ascending=False)

# Visualize the Decision Tree for specific max_depth values (e.g., 10, 20)
# depths_to_visualize = [5]
# for depth in depths_to_visualize:
#     plt.figure(figsize=(20, 10))
#     plot_tree(clfs[depth], filled=True, feature_names=features, class_names=label_encoders[target].classes_)
#     plt.title(f"Decision Tree (max_depth={depth})")
#     plt.show()
```

The accuracy of the model improved as the depth of the tree increased, with a max_depth of 25 or 30 providing the best test accuracy and Cohen's kappa reaching up to approximatively 70%. A max_depth of 5 resulted in significantly lower accuracy, indicating that it is not the optimal choice. A max_depth of 10 or 15 seems to be the best compromise between overall accuracy and avoiding overfitting. This pruning helps to improve the generalisation performance of the model by preventing it from becoming too complex and overfitting the training data.

### Variable Importance 

As we have used a classification tree for the prediction, the most important variable in the model are the ones at the top of the graph. Let's visualize the ranking of the features importance. 

```{python}
# Visualize the feature importances
plt.figure(figsize=(10, 6))
plt.barh(importances_df['Feature'], importances_df['Importance'], color='skyblue')
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance in Pruned Decision Tree')
plt.gca().invert_yaxis()  # To display the most important feature at the top
plt.show()

# Print the sorted feature importances
# print(importances_df)
```

We can see that among the top 3 most important features figure in order : the engine displacement, the model of the year and the class of the vehicle. On another hand, we can see that some features such as range_ev_city_fuel_type_2, range_ev_highway_fuel_type_2 and range_ev_city_fuel_type_1 are not important for our model for making predictions. This is certainly due to the quantity of EV and hybrid cars in the dataset and these features that are only concerning these types of vehicles.

### With Re-Sampling 

In order to fight class unbalances, we have decided to Re-Sample our dataset.

```{r, message = FALSE, echo=FALSE}

# Load the dataset in R
data <- read_csv(here("data","data_cleaned_reduced.csv"))

#nb of occurences per make
nb_model_per_make <- data %>%
  group_by(make) %>%
  summarise(Number = n(), .groups = 'drop')

#filter for re-sampling
nb_model_per_make <- nb_model_per_make %>%
  filter(Number > 1000)

# Determine the target number of occurrences for resampling (e.g., maximum occurrences of a single make)
target_occurrences <- max(nb_model_per_make$Number) # 4239

# Initialize an empty dataframe to store the resampled data
resampled_data <- data.frame()

# Perform resampling for each make
for (make_name in nb_model_per_make$make) {
  make_data <- data %>% filter(make == make_name)

  if (nrow(make_data) < target_occurrences) {
    # Resample with replacement if the number of occurrences is less than the target
    resampled_make_data <- make_data[sample(nrow(make_data), target_occurrences, replace = TRUE), ]
  } else {
    # If the number of occurrences is already sufficient, use the original data
    resampled_make_data <- make_data
  }

  # Combine the resampled data
  resampled_data <- rbind(resampled_data, resampled_make_data)
}

# Display the number of occurrences per make in the resampled dataset
table(resampled_data$make)

# Save the cleaned dataset
write_csv(resampled_data,
          here("data","resampled_data.csv"))

```

```{python, echo = FALSE}

# Load the dataset
file_path = here("data/resampled_data.csv")
data = pd.read_csv(file_path)

# Preprocess the data
# Assuming 'make' is the target variable and all other columns are features
target = 'make'
features = data.columns.drop(target)

# Encode categorical variables
label_encoders = {}
for column in data.columns:
    if data[column].dtype == 'object':
        le = LabelEncoder()
        data[column] = le.fit_transform(data[column])
        label_encoders[column] = le
        
        # Split the data into training and testing sets
X = data[features]
y = data[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Combine the train and test data for visualization
train_data = X_train.copy()
train_data[target] = y_train
train_data['Set'] = 'Train'

test_data = X_test.copy()
test_data[target] = y_test
test_data['Set'] = 'Test'

combined_data = pd.concat([train_data, test_data])

# Train the Decision Tree without specifying max_depth
clf_no_prune = DecisionTreeClassifier(random_state=42)
clf_no_prune.fit(X_train, y_train)

# Predict and calculate accuracies
y_pred_train_no_prune = clf_no_prune.predict(X_train)
y_pred_test_no_prune = clf_no_prune.predict(X_test)
accuracy_train_no_prune = accuracy_score(y_train, y_pred_train_no_prune)
accuracy_test_no_prune = accuracy_score(y_test, y_pred_test_no_prune)
kappa_train_no_prune = cohen_kappa_score(y_train, y_pred_train_no_prune)
kappa_test_no_prune = cohen_kappa_score(y_test, y_pred_test_no_prune)

print(f"Training Accuracy (without max_depth): {accuracy_train_no_prune:.4f}")
print(f"Test Accuracy (without max_depth): {accuracy_test_no_prune:.4f}")
print(f"Test Cohen's Kappa (without max_depth): {kappa_test_no_prune:.4f}")

# Visualize the Decision Tree without pruning
# plt.figure(figsize=(20, 10))
# plot_tree(clf_no_prune, filled=True, feature_names=features, class_names=label_encoders[target].classes_)
# plt.title("Decision Tree (without max_depth)")
# plt.show()
```

We notice that thanks to the Re-Sampling, we overfitting seems to have disappeared even if it was not the first intention. In addition, as shown, the classes are now balanced. Therefore, the chances of returning any class is equally distributed. 

